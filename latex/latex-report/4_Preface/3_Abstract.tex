%================================================================
%------------------------- Abstract -----------------------------
%================================================================
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\thispagestyle{plain}

%Limit the abstract to as few words as possible. The abstract should always be less than one page long, and less than 400 words. Be aware that many online referencing systems only allow the first 200 words to be included. No figures or references should be presented.Avoid extensive technical and method details where possible. Should be readable to a literate science reader familiar with your general area, but not necessarily experts-only material. 

A central challenge in building a mechanistic model of neural dynamics is to identify the model parameters consistent with experimental data. Due to intractable likelihoods, traditional methods in the toolkit of statistical inference are inaccessible for many mechanistic models. To overcome intractable likelihoods, simulation-based inference provides a framework for performing rigorous Bayesian inference by just requiring forward simulations of the model. The objective of this thesis is to investigate the viability of simulation-based inference, in particular approximate Bayesian computation (ABC) and neural density estimation (NDE), for identifying parameters in mechanistic models of neural dynamics. Specifically, we infer the conductance parameters in the Hodgkin-Huxley model for initiation and propagation of action potentials and the synaptic weight parameters in the Brunel network model for activity dynamics in local cortical networks. 
\\
\indent We develop the generic Python library pyLFI which uses ABC with quantile-based rejection sampling and local linear regression adjustment for estimating the posterior distributions of model parameters. As the curse of dimensionality forces ABC to require a compression of data into low-level summary statistics, we use expert-crafted statistics of spiking activity. The choice of summary statistics is crucial, and we carry out a correlation analysis to select and weight summary statistics. On synthetic data, pyLFI efficiently estimates posterior distributions and recovers ground truth parameters. We extensively vary tuning parameters, and find that, with regression adjustment, we can accept more simulations without sacrificing substantial accuracy for the model parameters that are the most constrained by the summary statistics. %We extensively vary hyperparameters, and find that, with local linear regression adjustment, accepting between 30-50\% of simulations, depending on the complexity of the model, yields accurate posteriors at a reasonable computational cost. 
%The approach of pyLFI is compared to the newly developed machine learning tool Sequential Neural Posterior Estimation (SNPE), which trains an artificial neural network to map features of observed data to posteriors over parameters by using adaptively proposed model simulations. Inference on the Brunel network model demonstrates the power and flexibility of SNPE; by training on simulations that includes two of the network states, SNPE is able to accurately predict posteriors that correspond to the state of observed data.
The approach of pyLFI is compared to the recent NDE algorithm Sequential Neural Posterior Estimation (SNPE), which trains an artificial neural network to map features of observed data to posteriors over parameters by using adaptively proposed model simulations. Inference on the Brunel network model demonstrates the power and flexibility of SNPE; by training on simulations that includes two of the network states, SNPE is able to accurately predict posteriors that correspond to the network's state in the observed data.
\\
\indent In conclusion, we find that simulation-based inference is a powerful tool that can be applied to a wide range of computational investigations in neuroscience, which may help to both bridge the gap between mechanistic hypotheses and experimental neural data, and design better models of neural dynamics. However, there are challenges (and opportunities) ahead in scaling and automating simulation-based inference approaches, and the methods are simulation intensive. 
