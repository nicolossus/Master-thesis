%================================================================
\chapter{Methodology}\label{chap:methodology}
%================================================================

%================================================================
\section{Computation}
%================================================================

\subsection{Log densities}

To avoid computational overflows and underflows, one should compute with the logarithm of posterior densities whenever possible. Exponentiation should be performed only when necessary and as late as possible; for example, in the Metropolis algorithm, the required ratio of two densities (11.1) should be computed as the exponential of the difference of the log-densities \cite[p. 261]{BDA}

\subsection{Numerical integration} 


\subsection{MCMC-ABC}

Flip-ordering, accept prob first then simulation

MCMC-ABC was also implemented in pyLFI, however, in order to focus the study on the objective, it is not included in the following analyses as it would not give any significant insights into the questions we seek than the more naive rejection sampler would. 


\subsection{Distance function}

\textbf{Relevant papers:}

* H. Jung and P. Marjoram (2011). "Choice of Summary Statistic Weights in Approximate Bayesian Computation". \url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3192002/}
    * Develops a Genetic Algorithm that computes how one should weight the summary statistics 
    * Fairly advanced, so we won't implement their approach, but should be mentioned in thesis
* D. Prangle (2015). "Adapting the ABC distance function". \url{https://arxiv.org/pdf/1507.00874.pdf}
    * Methods for adaptive distances
    * Won't implement this either, but will use the weighted distance defined in the paper
* S. Druckmann et al. (2007) "A novel multiple objective optimization framework for constraining conductance-based neuron models by experimental data". 
    * MOO
    
    
In the ABC algorithms, each simulation is converted to a vector of summary statistics $\mathbf{s} = (s_1, s_2, ..., s_m)$ and a distance between this and the summary statistics of the observed data, $\mathbf{s}_{obs}$, is calculated. Parameters producing distances below some threshold are accepted and form a sample from an approximation to the posterior. 

However, without normalization of the summary statistics, we are comparing oranges with apples. The most variable summaries will dominate the distances because of their larger scales. Handling the scales of the summaries ... blabla ... important.  

Normalizing the summaries so that they vary over roughly the same scale can be achieved by using a weighted Euclidean distance: 

$$ d \left(\mathbf{s}, \mathbf{s}_{obs} \right) = \left[ \sum_{i=1}^m \left( \frac{s_i - s_{obs, i}}{\sigma_i} \right)^2 \right]^{1/2},$$

where $\sigma_i$ is an estimate of the prior predictive standard deviation of the $i$th summary statistic. A convenient estimate is the empirical standard deviation of simulated $s_i$ values. The normalization we acquire from scaling by $\sigma_i$ prevents the distances from being dominated by the most variable summaries.  

Furthermore, we should also weight the importance of the summary statistics ...

\subsection{Sensitivity analysis} 

pearson correlation coefficient

Use Pearson's Coefficient of Correlation to weight importance of summary statistics.

* This is a simple approach for producing weighted statistics 
    * Method developed by H. Jung and P. Marjoram (2011) is more advanced and likely better
* The correlation coefficient, $r$, relates $Y$ to $X$ 
* The squared correlation coefficient, $r^2$, indicates the proportion of variance in $Y$ that is shared with (or accounted for) by $X$.

**Cons of using Pearson's Coefficient of Correlation:**

* Assumes:
    1. Normality of data (meaning that the data should approximate the normal distribution; most data points should tend to hover close to the mean)
    2. Homoscedasticity (means ‘equal variances’), i.e. a situation in which the variance of the dependent variable is the same for all the data.
    3. Linearity; simply means that the data follows a linear relationship. 
* (2. and 3. can be checked visually by scatter plot)
* Is sensitive to outliers; outliers can can significantly skew the correlation coefficient and make it inaccurate. Outliers are also easy to spot visually from the scatter plot

* vekte utifra sensitivitet

\textbf{Relevant papers:}

H. Jung and P. Marjoram (2011). "Choice of Summary Statistic Weights in Approximate Bayesian Computation". \url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3192002/}

* Develops a Genetic Algorithm that computes how one should weight the summary statistics 

* Fairly advanced, so we won't implement their approach, but should be mentioned in thesis

\subsection{Summary statistics weights}

\textbf{Relevant papers:}

H. Jung and P. Marjoram (2011). "Choice of Summary Statistic Weights in Approximate Bayesian Computation". \url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3192002/}

* Develops a Genetic Algorithm that computes how one should weight the summary statistics 

* Fairly advanced, so we won't implement their approach, but should be mentioned in thesis

* S. Druckmann et al. (2007) "A novel multiple objective optimization framework for constraining conductance-based neuron models by experimental data". 

%================================================================
\section{Notes}
%================================================================

Tabs to open again:

\url{https://learning.oreilly.com/library/view/bayesian-analysis-with/9781789341652/0d1ffa98-7336-4d71-aade-88f0973f4b13.xhtml}

\url{https://arxiv.org/pdf/2012.09612.pdf?fbclid=IwAR1xmEDRcPKHvcHK2KtQ1FO0B8K_yqKRlbPwdYuw0vv3-jjBTTR3CnMQEgY}

\url{https://arxiv.org/pdf/1707.01254.pdf}

\url{https://arxiv.org/pdf/1202.3819.pdf}

\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1462356/pdf/12524368.pdf}

\url{https://github.com/pymc-devs/pymc-examples/blob/main/examples/diagnostics_and_criticism/posterior_predictive.ipynb}

\section{Choice of Priors}

\url{https://en.wikipedia.org/wiki/Prior_probability}


The choice of priors ... beyond the scope of this thesis. We will mainly be using flat (uniform) or informed (normal centered about the true value)

Non- and weakly informative priors, p. 51 and 55 in BDA

As we saw in sec coin flip, the influence of the prior diminishes as more data is available.  


See LFI for cognitive science book, Ch. 2.1

Although the steps listed above may give the impression that all likelihood- free algorithms are simple, this is unfortunately not the case. Many sophisticated techniques have been created in the hopes of increasing the efficiency of an algorithm on a given problem, and as one might expect, the efficiency of the algorithms below do vary by the type of problem to which they are applied. Because the algorithms we present later in this chapter are sometimes complex, we first introduce a few concepts at a high level by describing the different choices one can make at Steps 1, 2, or 3.


The model performance when using a chosen active sensing scheme is defined as the Root Mean Squared Error (RMSE) over the predicted measurements, the lower the RMSE, the better the model performance, and hence the more accurate the map.

The model accuracy can be evaluated by comparing the predicted measurements with respect to the ground truth values and evaluating the RMSE to associate a scalar value as a uniform performance measure for the model being considered.


Since a single estimate amount to only a single stochastic trial, we perform 10 trials to see the spread. prior predictive distribution 


distance 

\url{https://stats.stackexchange.com/questions/15289/when-to-use-weighted-euclidean-distance-and-how-to-determine-the-weights-to-use}


\subsection{Brunel Network}

\url{https://link.springer.com/content/pdf/10.1023/A:1008925309027.pdf}

\url{https://www.frontiersin.org/articles/10.3389/fninf.2018.00049/full}

. However, the analysis does predict the transition
toward such synchronized states as soon as the excitation starts to dominate over inhibition

%================================================================
\section{Post-Processing of Posterior Samples}\label{sec:post_processing}
%================================================================

Post-sampling Adjustment



%================================================================
\subsection{Regression Adjustment}\label{sec:reg_adjust}
%================================================================

%================================================================
\section{HH Feature Extraction}\label{sec:hh_feature_extract}
%================================================================

\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570085/pdf/fnins-01-007.pdf}



12.2 ms effective rfp

"Variability of Firing of Hodgkin-Huxley and FitzHugh-Nagumo Neurons with Stochastic Synaptic Input", David Brown, Jianfeng Feng, and Stuart Feerick 

%================================================================
\chapter{Computational Approach}\label{chap:computational}
%================================================================

See: Automatically Selecting a Suitable Integration Scheme for Systems of Differential Equations in Neuron Models

2.2. Choice of a Suitable Numeric Integration Scheme

3. REFERENCE IMPLEMENTATION

The use of the toolbox as a Python module is explained in detail in the README.md file of the git repository at \url{http://github.com/ nest/ode-toolbox}. Here, we demonstrate the use of the analysis toolbox by executing the script file ode\_analyzer.py in a stand-alone fashion for generating a solver specification for a conductance-based integrate-and-fire neuron with alpha-shaped postsynaptic conductances


Our presented framework is re-usable independently of NESTML and NEST. The source code is available under the terms of the GNU General Public License version 2 or later on GitHub at \url{https://github.com/nest/ode-toolbox/} and we hope that the code can serve both as a useful tool for neuroscientists today, and as a basis for a future community effort in developing a simulator-independent system for the analysis of neuronal model equations.


To simulate (1) as efficiently as possible, one wishes to minimize the number of evaluations
of the nonlinear functions ai and bi
. (This becomes especially important when d is large,
as is the case for large biological neural networks.) It is therefore desirable to use an
explicit numerical integrator that allows for large time step sizes while still producing
sufficiently accurate dynamics. One of the main obstacles to doing so is stiffness: when ai
is
a large negative number, a traditional explicit Runge–Kutta method (like Euler’s method)
becomes numerically unstable unless the time step size is very small. 


However, there is another obstacle to taking large time step sizes, having to do with
preserving the qualitative dynamics of neuronal spiking in the Hodgkin–Huxley model.
When the input current into a neuron is low, the membrane voltage is attracted to a
resting equilibrium; however, when the input current exceeds a threshold, the voltage begins
rapidly rising and falling periodically. These voltage spikes, called action potentials, are the
mechanism by which neurons send signals to one another. From a dynamical systems point
of view, this corresponds to a bifurcation: the “resting” fixed point becomes unstable, and
the system is attracted to a stable “spiking” limit cycle lying on a two-dimensional center
manifold (Hassard [12], Izhikevich [16]). In order to simulate these dynamics faithfully and
efficiently, it is therefore desirable that a numerical integrator be able to preserve these limit
cycles at large time step sizes. Yet, Euler’s method does a poor job of preserving limit cycles
in nonlinear dynamical systems, even for simple systems like the Van der Pol oscillator,
unless one takes very small time steps—even smaller than one would need for numerical
stability (Hairer and Lubich [8]).

%================================================================
\section{pyLFI}\label{sec:pylfi}
%================================================================

... example code ...

Most well-tested implementations will do a bit more than this under the hood, but the preceding function gives the gist of the expectation–maximization approach.

An ABC software should be flexible enough to accommodate the new developments of the field. Here, we introduce a generalist Python package \cw{pyLFI}. The price to pay for the generality and flexibility is that the simulation of data and the calculation of summary statistics are left to the users. 

There are already a few stable ABC Python packages with several samplers implemented, the perhaps most notable packages being ELFI and ABCpy. However, we opted to make our own for several reasons:
- gain a thourogh understanding of the inner workings (under-the-hood)
- gain control over the bayesian workflow 
- abcpy requires a highly specific input and is not versatile when it comes to certain customizations, like sum stats
- ELFI, the better option of the two in the authors opinion, is being actively developed (also a nuisance with sbi) and drastic changes may thus occur on a frequent basis
- lacks integration with proper analysis tools (mostly basic visual and numerical diagnosis tools)

What pylfi is and isn’t:
- not a collection of the most advanced samplers
- is parallelized, like both ELFI and ABCpy
- reproducable, by using prng. Note: a caveat of multiprocessing and prng is that exact reproducibility is only possible when the number of procceses is the same (e.g. 3 processes will not generate the exact same result as 4 for a given seed, but a new run with 3 will generate the same with the same seed)
- arviz integration
- seaborn integration
- flexible kde
- flexible post-processing


\textbf{Simulation-based inference} 

%[Adapted from SNPE paper 2, need to rewrite this a bit in order to not plagiarize]

To perform Bayesian parameter identification with pyLFI, four types of input need to be specified: 

\begin{enumerate}
    \item A mechanistic model. The model only needs to be specified through a simulator, that is that one can generate a simulation result $x$ for any parameters $\theta$. We do not assume access to the likelihood $p(x | \theta)$ or the equations or internals of the code defining the model, nor do we require the model to be differentiable. 
    \item A summary statistics calculator. The ABC algorithms require the use of summary statistics $S(x)=s$ calculated from the raw data $x$. 
    \item Observed data $x_0$ of the same form as the results $x$ produced by model simulations
    \item A prior distribution $\pi (\theta)$ describing the range of possible parameters. $\pi (\theta)$ could consist of upper and lower bounds for each parameter, or a more complex distribution incorporating mechanistic first principles or knowledge gained from previous inference procedures on other data. In our applications, we chose priors deemed reasonable or informed by previous studies (see Materials and methods), although setting such priors is an open problem in itself, and outside of the scope of this study.
\end{enumerate}

For each problem, the goal is to estimate the posterior distribution $\pi(\theta | x_0)$. Setting up the inference procedure requires three design choices: 
\begin{enumerate}
    \item A distance metric
    \item Tuning parameters. The number of tuning parameters depends on which ABC algorithm is being used. The central tuning parameter for all algorithms is the threshold $\epsilon$. For MCMC algorithms, there are additional tuning parameters like proposal density scale, burn-in iterations ++. 
    \item A simulation budget, i.e. the number of samples to generate. Running the simulator is generally the most time consuming part of the procedure, and the ABC methods require many simulator runs to accurately produce the posterior. 
\end{enumerate}

We emphasize that pyLFI is highly modular, that is, that the the inputs (data, the prior over parameters, the mechanistic model, the summary statistic calculator), and algorithmic components (distance metric, optimization approach) can all be modified and chosen independently. This allows neuroscientists to work with models which are designed with mechanistic principles–—and not convenience of inference–—in mind.
Furthermore, pyLFI is extendable and more powerful algorithms or optimization strategies can be seamlessly incorporated into the framework (though the actual implementation of the algorithms might be a challenge).



%================================================================
\section{Software Development}
%================================================================ 

\textbf{Why Python?}

\begin{enumerate}
    \item Open source
    \item Easy, flexible coding
    \item Plethora of available packages for visualizations and analysis
    \item Interfacing other programs/languages:
    \begin{itemize}
        \item NEURON (\url{www.neuron.yale.edu})
        \item NEST (\url{www.nest-initiative.org})
        \item BRIAN (\url{http://briansimulator.org})
    \end{itemize}
\end{enumerate}


%================================================================
\subsection{pyLFI}
%================================================================

\textbf{ABC samplers} 

\begin{enumerate}
    \item Pathos used for parallel mapping
    \item Parallel Random Number Generation: Pool and seeding \url{https://numpy.org/doc/stable/reference/random/parallel.html} 
    \item 
\end{enumerate}

implementing something random means relying on a pseudo Random Number Generator (RNG).

Advancing a RNG updates the underlying RNG state as-if a given number of calls to the underlying RNG have been made. In general there is not a one-to-one relationship between the number output random values from a particular distribution and the number of draws from the core RNG. This occurs for two reasons:

1. The random values are simulated using a rejection-based method and so, on average, more than one value from the underlying RNG is required to generate an single draw.

2. Not relevant

Parallel Random Number Generation (PRNG) 

Advancing the PRNG’s state

Most of the cryptographic PRNGs are counter-based, and so support advancing which increments the counter. Advancing a PRNG updates the underlying PRNG state as if a given number of calls to the underlying PRNG have been made. In general there is not a one-to-one relationship between the number output random values from a particular distribution and the number of draws from the core PRNG. This occurs for two reasons:

1. The random values are simulated using a rejection-based method and so, on average, more than one value from the underlying PRNG is required to generate a single draw.

2. The number of bits required to generate a simulated value differs from the number of bits generated by the underlying PRNG. For example, two 16-bit integer values can be simulated from a single draw of a 32-bit PRNG.

Advancing the PRNG state resets any pre-computed random numbers. This is required to ensure exact reproducibility.

A major advantage of this scheme is its amenability to parallelization. Because rejection sampling (lines 7–14) is performed independently for each particle, sampling can be divided between different threads/processes. The calculation of weights (lines 20–22) can also be parallelized once rejection sampling for the current posterior estimate has completed. In our Python implementation, this parallelization was accomplished through the use of the Pathos multiprocessing module

%================================================================
\subsection{NeuroModels}
%================================================================

\textbf{Hodgkin-Huxley}

\begin{enumerate}
    \item about solve\_ivp and choices 
    \item arrays and interp1d
    \item vtrap 
    \item Q10 correction
\end{enumerate}

\textbf{Extracting spiking features}

\begin{enumerate}
    \item find\_peaks: prominence etc 
    \item algorithms for finding features from peaks 
\end{enumerate} 

brunel net

parameters are specified as Quantity objects: these are essentially arrays or numbers with a unit of measurement attached.

The nice thing about Quantities is that once the unit is specified you don’t need to worry about rescaling the values to a common unit ‘cause Quantities takes care of this for you

\url{https://python-quantities.readthedocs.io/en/latest/}

%================================================================
\subsection{Documentation and Unit Testing}
%================================================================

Uses continuous integration (CI) workflows, facilitated by GitHub Actions, to build and test the projects directly.

Sphinx to build the documentation. Readthedocs hosts the documentation and build environment. 

PyPI to publish packages. 

%================================================================
\section{Method}\label{sec:Method}
%================================================================

%----------------------------------------------------------------
\subsection{Project Method 1}\label{sec:project method}
%----------------------------------------------------------------

% the LFI methods: used own implementations (pylfi) and well-managed Python packages (ABCpy, sbi). => one goal is to see how they compare
% optimization beyond the scope of this thesis => use the established tools for the final (complex) analyses. 