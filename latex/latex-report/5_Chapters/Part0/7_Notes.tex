

\section{Intro}

Inverse modelling, that is, the process of gathering information on a model and its parameters from measurements of what is being modelled, is important because it tell us about parameters that we cannot directly observe.



The nervous system is made up of a large number of elements that interact in a complex fashion. To understand how such a complex system functions requires the construction and analysis of computational models at many different levels. 


Computational modelling is fundamental to the scientific method providing a link between real world empirical evidence and conceptual predictions

All brains are composed of a huge variety of neuron and synapse types. In computational neuroscience we use models for mimicking the behavior of these elements and to gain an understanding of the brain's behavior by conducting simulation experiments in neural simulators. These models are usually defined by a set of variables which have either concrete values or use functions and differential equations that describe the temporal evolution of the variables.

 

To bridge the gap between the theory of neuronal networks and findings obtained by the analysis of experimental data, advances in computational neuroscience rely heavily on simulations of neuronal network models. 


Computational neuroscientists use mathematical models built on observational data to investigate what’s happening in the brain. Models can simulate brain activity from the behavior of a single neuron right through to the patterns of collective activity in whole neural networks. Collecting the experimental data is the first step, then the challenge becomes deciding which computer models best represent the data and can explain the underlying causes of how the brain behaves.

Researchers usually find the right model for their data through trial and error. This involves tweaking a model’s parameters until the model can reproduce the data of interest. But this process is laborious and not systematic. Moreover, with the ever-increasing complexity of both data and computer models in neuroscience, the old-school approach of building models is starting to show its limitations.

Now, Gonçalves, Lueckmann, Deistler et al. have designed an algorithm that makes it easier for researchers to fit mathematical models to experimental data. First, the algorithm trains an artificial neural network to predict which models are compatible with simulated data. After initial training, the method can rapidly be applied to either raw experimental data or selected data features. The algorithm then returns the models that generate the best match.

This newly developed machine learning tool was able to automatically identify models which can replicate the observed data from a diverse set of neuroscience problems. Importantly, further experiments showed that this new approach can be scaled up to complex mechanisms, such as how a neural network in crabs maintains its rhythm of activity. This tool could be applied to a wide range of computational investigations in neuroscience and other fields of biology, which may help bridge the gap between ‘data-driven’ and ‘theory-driven’ approaches.

ABC algorithms have been successfully applied to a wide range of problems with an complex or absent associated likelihood. There are, however, several pitfalls to be aware of. The approach is simulation intensive, requires tuning of the tolerance threshold, discrepancy function and weighting function, and suffers from a curse of dimensionality of the summary statistic.  

\section{Introduction}

The brain contains millions of neurons which are organized in different regions. 

\url{https://neuronaldynamics.epfl.ch/online/Ch12.html}

The brain contains millions of neurons which are organized in different brain areas, within a brain area in different subregions,



The nervous system is responsible for making us think, feel, and move. It is heavily studied but poorly understood. The ultimate goal of neuroscience is to understand how the entire nervous system functions. This requires a deep understanding of all levels of detail in the nervous system, from how a single ion channel works on a molecular level to how aging affects the brain as a whole. The spatial scale of neuroscience goes from the molecular dynamics of single ion channels at nanometer scales ( 10−9 m) up to the length of the longest nerves at meter scales. Similarly, the temporal scale goes from molecular dynamics at picosecond scales ( 10−12 s) to aging over the lifespan of humans (∼ 100 years). The complexity of the nervous systems and the wide range of different spatial and temporal scales we want to combine makes computational science an irreplaceable tool.


Simulation-based inference (SBI) seeks to identify parameter sets that a)
are compatible with prior knowledge and b) match empirical observations. Importantly,
SBI does not seek to recover a single ‘best’ data-compatible parameter set, but rather
to identify all high probability regions of parameter space that explain observed data,
and thereby to quantify parameter uncertainty. In Bayesian terminology, SBI aims to retrieve the posterior distribution over the parameters of interest. In contrast to conventional
Bayesian inference, SBI is also applicable when one can run model simulations, but no
formula or algorithm exists for evaluating the probability of data given parameters, i.e.
the likelihood.

\url{https://github.com/EliseJ/astroABC/blob/master/examples/intro.ipynb}

Computational modelling is fundamental to the scientific method providing a link between real world empirical evidence and conceptual predictions

All brains are composed of a huge variety of neuron and synapse types. In computational neuroscience we use models for mimicking the behavior of these elements and to gain an understanding of the brain's behavior by conducting simulation experiments in neural simulators. These models are usually defined by a set of variables which have either concrete values or use functions and differential equations that describe the temporal evolution of the variables.

\url{https://www.frontiersin.org/articles/10.3389/fninf.2018.00068/full}

organisms are algorithms

infohazard - https://www.nickbostrom.com/information-hazards.pdf

(Set context)

The human brain, with its 100 billion neurons, .. complicated 

This project is placed in the junction between biology, physics, numerical modeling and statistical learning 


At one of the junctions between biology, physics and numerical modeling we computational neuroscience. 

Computational neuroscience ... junction between biology, physics and numerical modeling. 

Computational neuroscience and machine learning. 

The following introduces the fundamental problem and objective of the master project and the methodology that will be applied as well.


With the LFI approach, we will examine two widely studied neuroscientific models; the Hodgkin-Huxley model and the Brunel network model. 


Inverse modelling, that is, the process of gathering information on a model and its parameters from measurements of what is being modelled, is important because it tell us about parameters that we cannot directly observe.  


DRUKCMANN, 2007 

Traditionally, by a process of educated guesswork and intuition, a set of values for the parameters describing the different ion channels that may exist in the neuron membrane is suggested and the model performance is compared to the actual experimental data. This process is repeated until a satisfactory match between the model and the experiment is attained.

As computers become more powerful and clusters of processors increasingly common, the computational resources available to a modeler steadily increase. Thus, the possibility of harnessing these resources to the task of constraining parameters of conductance-based compartmental models seems very lucrative. However, the crux of the matter is that now the evaluation of the quality of a simulation is left to an algorithm. The highly sophisticated comparison between a model performance and experimental trace(s) that the trained modeler performs by eye must be reduced to some formula.


% Computational neuroscience is driven by the development of models describing neuronal activity on different temporal and spatial scales, ranging from single cells (e.g., Koch and Segev, 2000; Izhikevich, 2004) to spiking activity in mesoscopic neural networks (e.g., Potjans and Diesmann, 2014; Markram et al., 2015), to whole-brain activity (e.g., Sanz Leon et al., 2013; Schmidt et al., 2018). In order to quantify the accuracy and credibility of the models they must be routinely validated against experimental data. \url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6305903/}

% We formally implement the workflow using a generic Python library that we introduce for validation tests on neural network activity data.

% To bridge the gap between the theory of neuronal networks and findings obtained by the analysis of experimental data, advances in computational neuroscience rely heavily on simulations of neuronal network models. 

require numerical evaluation of likelihoods

Likelihood-free inference provides a framework for performing rigorous Bayesian infer- ence using only forward simulations

there have been developed a suite of methods that bypass the evaluation of the likelihood function, called likelihood-free inference methods. These methods seek to directly estimate either the posterior or the likelihood, and require only the ability to generate data from the simulator to analyze the model in a fully Bayesian context.


However, 

most mechanistic models have intractable likelihoods, making traditional methods in the toolkit of statistical inference inaccessible.

Simulation-based inference, in particular Approximate Bayesian Computation,


All brains are composed of a huge variety of neuron and synapse types. In computational neuroscience we use models for mimicking the behavior of these elements and to gain an understanding of the brain's behavior by conducting simulation experiments in neural simulators. These models are usually defined by a set of variables which have either concrete values or use functions and differential equations that describe the temporal evolution of the variables.

Advances in computational neuroscience rely on the development of mechanistic models describing neural phenomena, and candidate models are validated by comparing with experiments. A central challenge in building a mechanistic model is to identify the parametrization of the system which gives the best fit to experimental data. The Bayesian paradigm of statistical inference provides a robust approach to identify parameters consistent with data. However, most mechanistic models have intractable likelihoods, making traditional methods in the toolkit of statistical inference inaccessible. Recent advances in probabilistic modelling have led to a large number of simulation-based inference algorithms 

 simulation-based inference algorithms which do not require numerical evaluation of likelihoods. for such likelihood-free algorithms ...

Approximate Bayesian Computation (ABC) are a family of likelihood-free inference methods that require only the ability to generate data from the model to analyze the model in a fully Bayesian context.

Approximate Bayesian Computation (ABC) are a family of likelihood-free inference algorithms which does not require numerical evaluation of likelihoods, only the ability 

using only forward simulations

Likelihood-free inference provides a framework for performing rigorous Bayesian infer- ence using only forward simulations,

A central challenge is to identify the parameters of the model which give the best fit to experimental data. 


While rejection ABC (REJ-ABC) uses the prior as a proposal distribution, the efficiency can be improved by using sequentially refined proposal distributions (SMC) (can be said about MCMC also?). We implemented REJ-ABC with quantile-based rejection. 
We extensively varied hyperparameters. We investigated linear regression adjustment (Blum and François, 2010) and the summary statistics approach
by Prangle et al. (2014). [SBI Benchmark]



Advances in computational neuroscience rely on the development of simulator models describing neural phenomena, and candidate models are validated by comparing with experiments. The principal challenge is often not to set up the model equations, but rather identifying the parametrization of the system which achieves an agreement between the model and experimental data. The Bayesian paradigm of statistical inference provides a robust approach to identify parameters consistent with data. Most simulator models have intractable likelihoods, making traditional methods in the toolkit of statistical inference inaccessible. 


Likelihood-free inference provides a framework for performing rigorous Bayesian infer- ence using only forward simulations, properly accounting for all physical and observa- tional effects that can be successfully included in the simulations. The key challenge for likelihood-free applications in cosmology, where simulation is typically expensive


tool identifies all parameters consistent with data

provide a way constraining
22 and selecting models of large scale brain networks from empirical data

The aim of mechanistic models in neuroscience is to explain neural phenomena in terms of causal mechanisms, and candidate models are validated by comparing with experiments. The main challenge is often not to set up the model equations, but rather identifying the parametrization of the system which achieves an agreement between the model and experimental data. The Bayesian paradigm of statistical inference provides a robust approach to parameter identification with quantified uncertainty. Most mechanistic models have intractable likelihoods, making traditional methods in the toolkit of statistical inference inaccessible. Approximate Bayesian Computation (ABC) are a family of likelihood-free inference methods that require only the ability to generate data from the model to analyze the model in a fully Bayesian context.

Approximate Bayesian Computation (ABC) are a family of likelihood-free inference algorithms which does not require numerical evaluation of likelihoods, only the ability 

Recent advances in probabilistic modelling have led to a large number of simulation-based inference algorithms which do not require nu- merical evaluation of likelihoods. 

but instead of
83 filtering out simulations,

While rejection ABC (REJ-ABC) uses the prior as a proposal distribution, the efficiency can be improved by using sequentially refined proposal distributions (SMC) (can be said about MCMC also?). We implemented REJ-ABC with quantile-based rejection. 
We extensively varied hyperparameters. We investigated linear regression adjustment (Blum and François, 2010) and the summary statistics approach
by Prangle et al. (2014). [SBI Benchmark]



Because of the curse of dimensionality, ABC requires a compression of the data into low-dimensional summary statistics. We use various summary statistics of neural data obtained from domain knowledge.  expert-crafted summary statistics of spiking activity. If powerful low-dimensional summary statistics are established, traditional techniques can still offer a reasonable performance.

MCMC ABC, which improves the sample efficiency compared to Rej ABC by being guided by a proposal distribution ... MCMC ABC has improved sample efficiency 



In this thesis, we have used ABC with rejection sampling (Rejection ABC) and

In this thesis we implement the generic Python library pyLFI which uses ABC with both rejection and Markov chain Monte Carlo (MCMC) sampling for parameter inference/identification. In particular, we infer the conductance parameters in the Hodgkin-Huxley model for initiation and propagation of action potentials and the synaptic weight parameters in the Brunel network model for activity dynamics in local cortical networks. 

In this thesis, we have used (rejection) ABC (rejection sampling) and (MCMC) ABC (importance sampling) for identifying the conductance parameters in the Hodgkin-Huxley model for initiation and propagation of action potentials and the synaptic weight parameters in the Brunel network model for activity dynamics in local cortical networks. 

The Hodgkin-Huxley formalism is used as basis for many biophysically detailed cell models ...

Many cell models are built on the Hodgkin-Huxley formalism ... so being able to accurately constrain model parameters

using Markov chain Monte Carlo (MCMC) sampling

%Mechanistic models in neuroscience aim to explain neural or behavioral phenomena in terms of causal mechanisms, and candidate models are validated by comparing with experiments. The main challenge is often not set up the model equations, but rather identifying the parametrization of the system which achieves an agreement between the model and experimental data. The Bayesian paradigm of statistical inference provides a robust approach to parameter identification with quantified uncertainty. Due to (having) intractable likelihoods, traditional methods in the toolkit of statistical inference are inaccessible for many mechanistic models. Approximate Bayesian Computation (ABC) is/are a family of likelihood-free inference methods that require only the ability to generate data from the model to analyze the model in a fully Bayesian context.

%To overcome intractable likelihoods, there have been developed a suite of methods that bypass the evaluation of the likelihood function, called likelihood-free inference methods. These methods seek to directly estimate either the posterior or the likelihood, and require only the ability to generate data from the simulator to analyze the model in a fully Bayesian context.



%Mechanistic models in neuroscience aim to explain neural or behavioral phenomena in terms of causal mechanisms, and candidate models are validated by investigating whether proposed mechanisms can explain how experimental data manifest(s). Many mechanistic models are defined implicitly through simulators, i.e. a set of dynamical equations, which can be run forward to generate data. A central challenge in building a mechanistic model is to identify the parametrization of the system which achieves an agreement between the model and experimental data. Due to intractable likelihoods, traditional methods in the toolkit of statistical inference are inaccessible for many mechanistic models. To overcome intractable likelihoods, there have been developed a suite of methods that bypass the evaluation of the likelihood function, called likelihood-free inference methods. These methods seek to directly estimate either the posterior or the likelihood, and require only the ability to generate data from the simulator to analyze the model in a fully Bayesian context.

%The Bayesian paradigm of statistical inference provides a robust approach to parameter identification with quantified uncertainty. Statistical inference uses the likelihood function to quantify the match between parameters and data by deriving estimators of the parameters from the data. Likelihoods can be derived for purely statistical models, but are generally intractable or computationally infeasible for simulation-based models. Hence are traditional methods in the toolkit of statistical inference inaccessible for many mechanistic models.




%Mechanistic models in neuroscience aim to explain neural or behavioral phenomena in terms of causal mechanisms, and candidate models are validated by investigating whether proposed mechanisms can explain how experimental data manifests. The mechanistic modelling is generally through the use of differential equations, and these models often have non-measurable parameters. A central challenge in building a mechanistic model is to identify the parametrization of the system which achieves an agreement between the model and experimental data.

%The Bayesian paradigm of statistical inference provides a robust approach to parameter identification with quantified uncertainty. Statistical inference uses the likelihood function to quantify the match between parameters and data by deriving estimators of the parameters from the data. In Bayesian inference, posterior beliefs about parameters are updated according to Bayes' theorem upon observing data.

%Many mechanistic models are defined implicitly through simulators, i.e. a set of dynamical equations, which can be run forward to generate data. Likelihoods can be derived for purely statistical models, but are generally intractable or computationally infeasible for simulation-based models. Hence are traditional methods in the toolkit of statistical inference inaccessible for many mechanistic models.

%To overcome intractable likelihoods, a suite of methods that bypass the evaluation of the likelihood function, called likelihood-free inference methods, have been developed. These methods seek to directly estimate either the posterior or the likelihood, and require only the ability to generate data from the simulator to analyze the model in a fully Bayesian context.


\section{elife}
Computational neuroscientists use mathematical models built on observational data to investigate what’s happening in the brain. Models can simulate brain activity from the behavior of a single neuron right through to the patterns of collective activity in whole neural networks. Collecting the experimental data is the first step, then the challenge becomes deciding which computer models best represent the data and can explain the underlying causes of how the brain behaves.

Researchers usually find the right model for their data through trial and error. This involves tweaking a model’s parameters until the model can reproduce the data of interest. But this process is laborious and not systematic. Moreover, with the ever-increasing complexity of both data and computer models in neuroscience, the old-school approach of building models is starting to show its limitations.

Now, Gonçalves, Lueckmann, Deistler et al. have designed an algorithm that makes it easier for researchers to fit mathematical models to experimental data. First, the algorithm trains an artificial neural network to predict which models are compatible with simulated data. After initial training, the method can rapidly be applied to either raw experimental data or selected data features. The algorithm then returns the models that generate the best match.

This newly developed machine learning tool was able to automatically identify models which can replicate the observed data from a diverse set of neuroscience problems. Importantly, further experiments showed that this new approach can be scaled up to complex mechanisms, such as how a neural network in crabs maintains its rhythm of activity. This tool could be applied to a wide range of computational investigations in neuroscience and other fields of biology, which may help bridge the gap between ‘data-driven’ and ‘theory-driven’ approaches.

\section{Bayesian}
%================================================================
%\subsubsection{With Unknown Mean and Variance}
%================================================================

%The comprehensive derivation can be found in appendix B. 




%================================================================
%\section{The Influence of the Prior and How to Choose One}\label{sec:prior}
%================================================================

%\url{http://www.stat.columbia.edu/~gelman/research/published/p039-_o.pdf}

%\begin{itemize}
%    \item Flat
%    \item Uninformative
%    \item Diffuse
%    \item The Jeffreys’ Prior: Suppose we cannot easily find the natural scale on which the likelihood is in data-translated format, or that such a decomposition does not exist. Jeffreys (1961) proposed a general prior in such cases, based on the Fisher information I of the likelihood. 
%    \item When a prior distribution is not integrable it is said to be \textit{improper}
%\end{itemize}


%================================================================
%\subsection{Conjugate Prior Distributions}
%================================================================

%In Bayesian probability theory, if posterior distributions are in the same family as the prior distributions, then both prior and posterior are called conjugate distributions and the prior is called conjugate prior.

%Conjugacy is formally defined as follows. If $\mathcal{F}$ is a class of sampling distributions $p \left(y | \theta \right)$, and $\mathcal{P}$ is a class of prior distributions for $\theta$, then the class $\mathcal{P}$ is \textit{conjugate} for $\mathcal{F}$ if

%\begin{equation}
%    \pi \left(\theta | y \right) \in \mathcal{P} \, \forall p \left(\cdot | \theta \right) \in \mathcal{F} \land \pi (\cdot) \in \mathcal{P}
%\end{equation}

%This definition is formally vague since if we choose $\mathcal{P}$ as the class of all distributions, then $\mathcal{P}$ is always conjugate no matter what class of sampling distributions is used. We are most interested in \textit{natural} conjugate prior families, which arise by taking $\mathcal{P}$ to be the set of all densities having the same functional form as the likelihood \cite{ABC_ch1}.

%A conjugate prior of a likelihood is a prior that, when used in combination with a given likelihood, returns a posterior with the same functional form as the prior. cite BAP

%================================================================
%\section{Prior and Posterior Predictive Checks}
%================================================================

%\begin{itemize}
    %\item \url{https://docs.pymc.io/notebooks/posterior_predictive.html}
    %\item \url{https://avehtari.github.io/masterclass/slides_ppc.pdf}
    %\item \url{https://vasishth.github.io/bayescogsci/book/sec-priorpred.html}
    %\item \url{https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html#113_Prior_Predictive_Checks}
    %\item \url{http://bebi103.caltech.edu.s3-website-us-east-1.amazonaws.com/2018/tutorials/t6a_model_generation_and_prior_predictive_checks.html} python
%\end{itemize}

%================================================================
%\section{Uncertainty/Sensitivty Analysis in the Bayesian Paradigm}
%================================================================






%================================================================
%\subsection{The Prior and Posterior Predictive Distributions}\label{sec:predictive}
%================================================================

%BDA, side 7



\section{Notes from abstract}

A central challenge in building a mechanistic model of neural dynamics is to identify the model parameters consistent with experimental data. Due to intractable likelihoods, traditional methods in the toolkit of statistical inference are inaccessible for many mechanistic models. To overcome intractable likelihoods, simulation-based inference provides a framework for performing rigorous Bayesian inference without requiring numerical evaluation of likelihoods by using only forward simulations. The objective of this thesis is to investigate the viability of simulation-based inference, in particular approximate Bayesian computation (ABC) algorithms, for identifying parameters in mechanistic models of neural dynamics. Specifically, we use rejection ABC (REJ-ABC) and Markov chain Monte Carlo ABC (MCMC-ABC) to infer the conductance parameters in the Hodgkin-Huxley model for initiation and propagation of action potentials and the synaptic weight parameters in the Brunel network model for activity dynamics in local cortical networks. 

and for designing better models of neural dynamics.

In conclusion, we find that simulation-based inference provides a principled approach for determining parameters consistent with empirical observations, and can be applied to a wide range of computational investigations in neuroscience and other fields. 

Simulation-based inference, although simulation intensive

However, scalability

This tool could be applied to a wide range of computational investigations in neuroscience and other fields of biology, which may help bridge the gap between ‘data-driven’ and ‘theory-driven’ approaches.

There are challenges and opportunities ahead in further scaling and automating simulation-based inference approaches. However, in its current form, SNPE will be a powerful tool for quantitatively evaluating mechanistic hypotheses on neural data, and for designing better models of neural dynamics.

Method remains simulation intensive, in particular ABC where many simulations are rejected, 


---

The posteriors obtained via pyLFI are compared to posteriors obtained via the newly developed machine learning tool Sequential Neural Posterior Estimation (SNPE), which trains an artificial neural network to map features of observed data to posteriors over parameters by using adaptively proposed model simulations. 


which uses adaptively proposed model simulations to train an artificial neural network to map features of the observed data to posteriors over parameters. Inference on the Brunel network model demonstrates the power and flexibility of SNPE; by training on simulations that includes 

to predict parameter posteriors given 

Our approach builds on recent advances in ABC by learning a neural network which maps features of the observed data to the poste- rior distribution over parameters. We learn a Bayesian mixture-density network approximating the posterior over multiple rounds of adaptively chosen simulations.




learn a Bayesian mixture-density network approximating the posterior over multiple rounds of adaptively chosen simulations.


SNPE uses simulations of the model to train an artificial neural network to predict which models are 


trains an artificial neural network to predict which models are compatible with simulated data. After initial training, the method can rapidly be applied to either raw experimental data or selected data features. The algorithm then returns the models that generate the best match. 

On synthetic data, the aforementioned simulation-

On synthetic data, our approach efficiently estimates posterior distributions and recovers ground-truth parameters.

In conclusion, we find that simulation-based inference provides a principled approach for determining parameters consistent with empirical observations, and can be applied to a wide range of computational investigations in neuroscience and other fields. 

However, scalability

This tool could be applied to a wide range of computational investigations in neuroscience and other fields of biology, which may help bridge the gap between ‘data-driven’ and ‘theory-driven’ approaches.

There are challenges and opportunities ahead in further scaling and automating simulation-based inference approaches. However, in its current form, SNPE will be a powerful tool for quantitatively evaluating mechanistic hypotheses on neural data, and for designing better models of neural dynamics.

Method remains simulation intensive, in particular ABC where many simulations are rejected, 

----

 methods for estimating the posterior distributions of model parameters.

In this thesis we implement the generic Python library pyLFI which uses ABC with both rejection

Specifically, we use rejection ABC (REJ-ABC) and Markov chain Monte Carlo ABC (MCMC-ABC) to infer the conductance parameters in the Hodgkin-Huxley model for initiation and propagation of action potentials and the synaptic weight parameters in the Brunel network model for activity dynamics in local cortical networks. 



Bayesian inference is a principled approach for determining parameters consistent with empirical observations


It also has the
advantage of returning an entire posterior distribution on the
value of the parameters, rather than a simple point estimate

implement the generic Python library pyLFI 

We implemented REJ-ABC with quantile-based rejection



As the curse of dimensionality forces ABC to require a compression of data into low-level summary statistics, we use expert-crafted statistics of spiking activity. The choice of summary statistics is crucial, and we carried out a sensitivity analysis to select and weight summary statistics. We extensively varied hyperparameters, and found that, with local linear regression adjustment, accepting between 30-50\% of simulations, depending on the model, yields accurate posteriors at a reasonable computational cost.  



While rejection ABC (REJ-ABC) uses the prior as a proposal distribution, the efficiency can be improved by using sequentially refined proposal distributions (SMC) (can be said about MCMC also?). We implemented REJ-ABC with quantile-based rejection. 
We extensively varied hyperparameters. We investigated linear regression adjustment (Blum and François, 2010) and the summary statistics approach
by Prangle et al. (2014). [SBI Benchmark]



Because of the curse of dimensionality, ABC requires a compression of the data into low-dimensional summary statistics. We use various summary statistics of neural data obtained from domain knowledge.  expert-crafted summary statistics of spiking activity. If powerful low-dimensional summary statistics are established, traditional techniques can still offer a reasonable performance.

MCMC ABC, which improves the sample efficiency compared to Rej ABC by being guided by a proposal distribution ... MCMC ABC has improved sample efficiency 



In this thesis, we have used ABC with rejection sampling (Rejection ABC) and

In this thesis we implement the generic Python library pyLFI which uses ABC with both rejection and Markov chain Monte Carlo (MCMC) sampling for parameter inference/identification. In particular, we infer the conductance parameters in the Hodgkin-Huxley model for initiation and propagation of action potentials and the synaptic weight parameters in the Brunel network model for activity dynamics in local cortical networks. 

In this thesis, we have used (rejection) ABC (rejection sampling) and (MCMC) ABC (importance sampling) for identifying the conductance parameters in the Hodgkin-Huxley model for initiation and propagation of action potentials and the synaptic weight parameters in the Brunel network model for activity dynamics in local cortical networks. 

The Hodgkin-Huxley formalism is used as basis for many biophysically detailed cell models ...

Many cell models are built on the Hodgkin-Huxley formalism ... so being able to accurately constrain model parameters

using Markov chain Monte Carlo (MCMC) sampling

We were able to accurately constrain the conductance parameters of the Hodgkin-Huxley model as we obtained narrow posteriors with the ground truth parameters in regions of high posterior density. 
For the Hodgkin-Huxley model we obtain narrow posteriors with the true parameters in regions of high posterior density, indicating that ABC is a viable method for parameter identification in the many cell models built on the Hodgkin formalism. 

As we only investigated models with few parameters, the viability of ABC on high-dimensional problems is yet to explore. 


REJ-ABC with local linear regression adjustment were able to constrain the potassium conductance $\bar{g}_\mathrm{K}$ to the credible interval ... (ground truth $\bar{g}_\mathrm{K} = 36$ and the sodium conductance $\bar{g}_\mathrm{Na}$ to the credible interval ... (ground truth $\bar{g}_\mathrm{Na} = 120$).

ABC requires some tuning to achieve different levels of accuracy, which can be time consuming as neural models generally are computationally expensive. 